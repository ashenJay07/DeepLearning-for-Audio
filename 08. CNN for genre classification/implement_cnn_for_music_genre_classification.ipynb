{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbd5992c-443d-4791-a78b-e1a5a349da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d60d7da-7c79-4afc-b573-3a1e59540a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"audio_data.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f8705-e4db-4ce5-ad7a-bc1be4045be1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Load data from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5b9fa1b-940b-4259-ae3c-7aa762afef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc6bb8-f4af-4558-8067-bfc8590ca669",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4eaf511-2f42-4c65-b58d-153563cd7a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(test_size, validation_size):\n",
    "    # load data\n",
    "    X, y = load_data(DATA_PATH)\n",
    "\n",
    "    # create train & test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    # create train & validation sets\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "\n",
    "    # for CNN, tensorflow expect 3D array for each sample\n",
    "    # Modifying datasets by adding 3rd dimension (# of channels)\n",
    "    X_train = X_train[..., np.newaxis]  # This returns 4D array => (num_samples, 130, 13, 1)\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "\n",
    "    # In (num_samples, 130, 13, 1),\n",
    "    #     (num_samples, 130, 13, 1) = shape of the each sample of X_train\n",
    "    #     130 = time bins\n",
    "    #     13 = MFCC value we take for each time bin\n",
    "\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f5f77-b0e8-41b5-b663-52de2da06430",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e3b6365-7f05-4b20-9cc4-0f8b70e26fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    # create model\n",
    "    model = keras.Sequential()\n",
    "        \n",
    "    # 1st convolution layer\n",
    "    # model.add(keras.layers.Conv2D(# of kernel we use, grid size of kernel, type of activation, input_shape))\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))  # relu should be lowercase\n",
    "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    # 2nd convolution layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    # 3rd convolution layer\n",
    "    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    # flatten the output and feed it into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))  # 64 = number of neurons that we wants\n",
    "    model.add(keras.layers.Dropout(0.3))  # flatten\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365681a8-43e6-490c-b4f6-455b7e1ecfee",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Define a method for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e2abaf0-7891-40ce-a0c5-6ec7a7dbc8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y):\n",
    "    X = X[np.newaxis, ...]\n",
    "\n",
    "    # prediction = 2D array => [[0.1, 0.2, ...]]\n",
    "    prediction = model.predict(X, y)  # X => (1, 130, 13, 1)\n",
    "\n",
    "    # extract index with max value\n",
    "    predicted_index = np.argmax(prediction, axis=1)  # [4]\n",
    "    print(\"\\n\\nExpected index: {}, Predicted index: {}\".format(y, predicted_index))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65799fa0-c8fa-4339-aacf-91eb0a14762c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Utilize the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1eff54ed-99fd-44fe-9d24-86fce72bea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 [==============================] - 2s 7ms/step - loss: 2.4423 - accuracy: 0.2248 - val_loss: 1.8866 - val_accuracy: 0.3605\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.8736 - accuracy: 0.3607 - val_loss: 1.5437 - val_accuracy: 0.4526\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.6621 - accuracy: 0.4098 - val_loss: 1.4242 - val_accuracy: 0.4800\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.5169 - accuracy: 0.4587 - val_loss: 1.3256 - val_accuracy: 0.5093\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.4346 - accuracy: 0.4852 - val_loss: 1.2508 - val_accuracy: 0.5387\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.3787 - accuracy: 0.4992 - val_loss: 1.2144 - val_accuracy: 0.5607\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.3149 - accuracy: 0.5290 - val_loss: 1.1523 - val_accuracy: 0.5854\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.2463 - accuracy: 0.5502 - val_loss: 1.1064 - val_accuracy: 0.5981\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.2135 - accuracy: 0.5640 - val_loss: 1.0845 - val_accuracy: 0.6015\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.1687 - accuracy: 0.5850 - val_loss: 1.0542 - val_accuracy: 0.6095\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 1.1314 - accuracy: 0.5977 - val_loss: 1.0278 - val_accuracy: 0.6315\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.1033 - accuracy: 0.6021 - val_loss: 1.0003 - val_accuracy: 0.6415\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.0735 - accuracy: 0.6189 - val_loss: 1.0110 - val_accuracy: 0.6268\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.0494 - accuracy: 0.6226 - val_loss: 0.9664 - val_accuracy: 0.6462\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.0085 - accuracy: 0.6381 - val_loss: 0.9545 - val_accuracy: 0.6562\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.9892 - accuracy: 0.6488 - val_loss: 0.9227 - val_accuracy: 0.6696\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.9660 - accuracy: 0.6612 - val_loss: 0.9108 - val_accuracy: 0.6816\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.9381 - accuracy: 0.6697 - val_loss: 0.8974 - val_accuracy: 0.6722\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.9181 - accuracy: 0.6772 - val_loss: 0.9020 - val_accuracy: 0.6689\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.8971 - accuracy: 0.6887 - val_loss: 0.8709 - val_accuracy: 0.6876\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.8902 - accuracy: 0.6820 - val_loss: 0.8747 - val_accuracy: 0.6923\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.8617 - accuracy: 0.6985 - val_loss: 0.8615 - val_accuracy: 0.6809\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.8445 - accuracy: 0.7059 - val_loss: 0.8633 - val_accuracy: 0.6769\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.8135 - accuracy: 0.7129 - val_loss: 0.8614 - val_accuracy: 0.6943\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.8149 - accuracy: 0.7092 - val_loss: 0.8222 - val_accuracy: 0.7043\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.7796 - accuracy: 0.7261 - val_loss: 0.8116 - val_accuracy: 0.7103\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.7800 - accuracy: 0.7202 - val_loss: 0.8037 - val_accuracy: 0.7123\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.7604 - accuracy: 0.7348 - val_loss: 0.7946 - val_accuracy: 0.7150\n",
      "Epoch 29/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.7390 - accuracy: 0.7349 - val_loss: 0.7795 - val_accuracy: 0.7163\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.7288 - accuracy: 0.7471 - val_loss: 0.7823 - val_accuracy: 0.7203\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8602 - accuracy: 0.7109\n",
      "\n",
      "\n",
      "Accuracy on test set is: 0.7108530402183533\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "\n",
      "\n",
      "Expected index: 7, Predicted index: [7]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # create train & validation and test sets\n",
    "    X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)\n",
    "    \n",
    "    # build the CNN network\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])  # 4D => 3D \n",
    "    model = build_model(input_shape)\n",
    "    \n",
    "    # compile the network\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train the CNN\n",
    "    model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)\n",
    "    \n",
    "    # evaluate the CNN on the test set\n",
    "    test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(\"\\n\\nAccuracy on test set is: {}\".format(test_accuracy))\n",
    "\n",
    "    # make prediction on a sample\n",
    "    X = X_test[100]\n",
    "    y = y_test[100]\n",
    "    predict(model, X, y)  # In here, model = trained model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_kernel",
   "language": "python",
   "name": "tf_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
