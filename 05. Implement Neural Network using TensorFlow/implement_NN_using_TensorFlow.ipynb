{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from random import random\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "aOKH-X8rRxbl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "urLEivxoQ6sL"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(num_samples, test_size=0.3):\n",
        "  # Create dataset\n",
        "  x = np.array([[random() / 2 for _ in range(2)] for _ in range(num_samples)])\n",
        "  y = np.array([[i[0] + i[1]] for i in x])\n",
        "\n",
        "  # Create training and testing sets\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n",
        "  return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  x_train, x_test, y_train, y_test = generate_dataset(5000, 0.2)\n",
        "\n",
        "  # print(\"x_test: \\n{}\\n\".format(x_test))  # 2 x 2 matrix\n",
        "  # print(\"y_test: \\n{}\".format(y_test))  # 2 x 1 matrix\n",
        "\n",
        "  # Build model: 2 -> 5 -> 1\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(5, input_dim=2, activation='sigmoid'),  # Hidden-layer\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')  # Output-layer\n",
        "  ])\n",
        "\n",
        "  # Compile model\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)  # SGD - Stochastic Gradient Descent\n",
        "  model.compile(optimizer=optimizer, loss='MSE')  # loss means error\n",
        "\n",
        "  # Train model\n",
        "  model.fit(x_train, y_train, epochs=100)\n",
        "\n",
        "  # Evaluate model\n",
        "  print('\\n\\n======================= Model Evaluation =======================')\n",
        "  model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  # Make predictions\n",
        "  data = np.array([[0.1, 0.2], [0.3, 0.6]])\n",
        "  predictions = model.predict(data)\n",
        "\n",
        "  print('\\n\\n======================= Predictions =======================')\n",
        "  for data, pred in zip(data, predictions):\n",
        "    print(\"{} + {} = {}\".format(data[0], data[1], pred[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSGYihdzSDmJ",
        "outputId": "bd1999ca-5eeb-474c-8797-2af59f14e022"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0624\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0418\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0415\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0413\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0410\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0408\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0405\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0402\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0400\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0397\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0394\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0391\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0388\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0385\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0381\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0377\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0374\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0370\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0366\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0361\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0356\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0352\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0346\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0341\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0335\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0329\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0323\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0317\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0310\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0303\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0295\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0288\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0280\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0272\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0264\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0255\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0246\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0238\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0229\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0219\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0211\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0201\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0192\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0183\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0174\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0165\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0157\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0148\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0132\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0124\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0117\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0110\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0103\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0096\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0090\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0084\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0063\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0059\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0055\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0051\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0047\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0044\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0041\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0038\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0035\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0033\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0031\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0029\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0027\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0022\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0018\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0017\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0010\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 9.8841e-04\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 9.4016e-04\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 8.9613e-04\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 8.5516e-04\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 8.1819e-04\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 7.8370e-04\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 7.5209e-04\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 7.2309e-04\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 6.9650e-04\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 6.7205e-04\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 6.4946e-04\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 6.2874e-04\n",
            "\n",
            "\n",
            "======================= Model Evaluation =======================\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 6.5198e-04\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "\n",
            "\n",
            "======================= Predictions =======================\n",
            "0.1 + 0.2 = 0.3036034405231476\n",
            "0.3 + 0.6 = 0.8290285468101501\n"
          ]
        }
      ]
    }
  ]
}